{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "56fef95b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 339
    },
    "id": "56fef95b",
    "outputId": "9e484ee6-aa5a-488b-8b5a-98b403437d42"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-17 12:11:57.750801: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-04-17 12:11:57.750849: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "/usr/lib/python3/dist-packages/Crypto/Random/Fortuna/FortunaGenerator.py:28: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if sys.version_info[0] is 2 and  sys.version_info[1] is 1:\n",
      "/usr/lib/python3/dist-packages/Crypto/Random/Fortuna/FortunaGenerator.py:28: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if sys.version_info[0] is 2 and  sys.version_info[1] is 1:\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "# tf.get_logger().setLevel('INFO')\n",
    "from functools import partial\n",
    "import matplotlib.pyplot as plt\n",
    "import IPython.display as display\n",
    "import numpy as np\n",
    "# import tensorflow_addons as tfa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec30b895",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ec30b895",
    "outputId": "db6014ff-5597-4161-9ad8-bb07192fc463"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of replicas: 1\n"
     ]
    }
   ],
   "source": [
    "strategy = tf.distribute.get_strategy()\n",
    "print(\"Number of replicas:\", strategy.num_replicas_in_sync)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "YShaVaxpqhx8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YShaVaxpqhx8",
    "outputId": "14804f98-345c-48de-df34-6874f7067a4f"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "650c9c9b",
   "metadata": {
    "id": "650c9c9b"
   },
   "source": [
    "# Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "96c4f70f",
   "metadata": {
    "id": "96c4f70f"
   },
   "outputs": [],
   "source": [
    "\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "BATCH_SIZE = 32\n",
    "# IMAGE_SIZE = [1024, 1024]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d6852bc8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d6852bc8",
    "outputId": "9c8a59a5-65c5-4e7a-9884-5f7c0538dfd8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train TFRecord Files: 69\n",
      "Validation TFRecord Files: 69\n",
      "Test TFRecord Files: 68\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "FILENAMES_PATH = \"American Sign Language Letters.v1-v1.tfrecord/\"\n",
    "\n",
    "TRAINING_FILENAMES =  FILENAMES_PATH + \"train/Letters.tfrecords\"\n",
    "VALID_FILENAMES = FILENAMES_PATH + \"valid/Letters.tfrecords\"\n",
    "TEST_FILENAMES = FILENAMES_PATH + \"test/Letters.tfrecords\"\n",
    "\n",
    "print(\"Train TFRecord Files:\", len(TRAINING_FILENAMES))\n",
    "print(\"Validation TFRecord Files:\", len(VALID_FILENAMES))\n",
    "print(\"Test TFRecord Files:\", len(TEST_FILENAMES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "732da708",
   "metadata": {
    "id": "732da708"
   },
   "outputs": [],
   "source": [
    "# example = TRAINING_FILENAMES\n",
    "labeled = FILENAMES_PATH + \"/train/Letters_label_map.pbtxt\"\n",
    "# print(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "901c1392",
   "metadata": {
    "id": "901c1392"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ae6f7622",
   "metadata": {
    "id": "ae6f7622"
   },
   "outputs": [],
   "source": [
    "# Create the dataset object for tfrecord file(s)\n",
    "\n",
    "def load_dataset(tf_filenames):\n",
    "    ignore_order = tf.data.Options()\n",
    "    ignore_order.experimental_deterministic = False  # disable order, increase speed\n",
    "    dataset = tf.data.TFRecordDataset(tf_filenames) \n",
    "    \n",
    "    dataset = dataset.with_options(ignore_order)  \n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c98b440a",
   "metadata": {
    "id": "c98b440a"
   },
   "outputs": [],
   "source": [
    "# Decoding function\n",
    "def parse_record(record):\n",
    "    tfrecord_feat_format = (\n",
    "                {\n",
    "                    \"image/encoded\": tf.io.FixedLenFeature([], tf.string),\n",
    "                    \"image/filename\": tf.io.FixedLenFeature([], tf.string),\n",
    "                    \"image/format\": tf.io.FixedLenFeature([], tf.string),\n",
    "                    \"image/height\": tf.io.FixedLenFeature([], tf.int64),\n",
    "                    \"image/object/bbox/xmax\": tf.io.FixedLenFeature([], tf.float32),\n",
    "                    \"image/object/bbox/xmin\": tf.io.FixedLenFeature([], tf.float32),\n",
    "                    \"image/object/bbox/ymax\": tf.io.FixedLenFeature([], tf.float32),\n",
    "                    \"image/object/bbox/ymin\": tf.io.FixedLenFeature([], tf.float32),\n",
    "                    \"image/object/class/label\": tf.io.FixedLenFeature([], tf.int64),\n",
    "                    \"image/object/class/text\": tf.io.FixedLenFeature([], tf.string),\n",
    "                    \"image/width\": tf.io.FixedLenFeature([], tf.int64),\n",
    "                }\n",
    "            )\n",
    "    \n",
    "    \n",
    "    \n",
    "    example = tf.io.parse_single_example(record, tfrecord_feat_format)\n",
    "\n",
    "\n",
    "\n",
    "    IMAGE_SIZE = [400, 400]\n",
    "\n",
    "    image =  tf.io.decode_jpeg(example[\"image/encoded\"], channels=3)\n",
    "    image = tf.cast(image, tf.float32)\n",
    "\n",
    "    xmax = tf.cast(example[\"image/object/bbox/xmax\"], tf.int32)\n",
    "    xmin = tf.cast(example[\"image/object/bbox/xmin\"], tf.int32)\n",
    "    ymax = tf.cast(example[\"image/object/bbox/ymax\"], tf.int32)\n",
    "    ymin = tf.cast(example[\"image/object/bbox/ymin\"], tf.int32)\n",
    "\n",
    "    box_width = xmax - xmin\n",
    "    box_height = ymax - ymin\n",
    "    image = tf.image.crop_to_bounding_box(image, ymin, xmin, box_height, box_width)\n",
    "    image = tf.image.convert_image_dtype(image, tf.float32)\n",
    "    image = tf.image.resize(image, IMAGE_SIZE)\n",
    "\n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "    # image = tfa.image.rotate(image, 40, interpolation='NEAREST')\n",
    "\n",
    "\n",
    "    # image = tf.cast(image, \"uint8\")\n",
    "    # image = tf.image.encode_jpeg(image, format='rgb', quality=100)\n",
    "    \n",
    "\n",
    "    label = example[\"image/object/class/label\"]\n",
    "    label = tf.cast(label, tf.int32)\n",
    "    # label = tf.one_hot(label, depth=26)\n",
    "\n",
    "    \n",
    "    return (image, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0824b3b4",
   "metadata": {
    "id": "0824b3b4"
   },
   "outputs": [],
   "source": [
    "def get_dataset(filenames):\n",
    "    ignore_order = tf.data.Options()\n",
    "    ignore_order.experimental_deterministic = False  # disable order, increase speed\n",
    "    dataset = tf.data.TFRecordDataset(filenames) \n",
    "    \n",
    "    dataset = dataset.with_options(ignore_order) \n",
    "    \n",
    "    dataset = dataset.map(parse_record, num_parallel_calls=AUTOTUNE)\n",
    "    dataset = dataset.cache()\n",
    "    \n",
    "    dataset = dataset.shuffle(buffer_size=10 * BATCH_SIZE, reshuffle_each_iteration=True)\n",
    "    dataset = dataset.batch(BATCH_SIZE)\n",
    "    dataset = dataset.prefetch(buffer_size=AUTOTUNE)\n",
    "    # dataset = dataset.repeat()\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8e849ae8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8e849ae8",
    "outputId": "039d4ce7-f77b-4c7e-ecfa-83cde8497641"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<PrefetchDataset shapes: ((None, 400, 400, 3), (None,)), types: (tf.float32, tf.int32)>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tfr_dataset = get_dataset(TRAINING_FILENAMES)\n",
    "print(tfr_dataset)\n",
    "\n",
    "tfr_testdata = get_dataset(VALID_FILENAMES)\n",
    "print(tfr_testdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e1e175e9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e1e175e9",
    "outputId": "dbbb3bca-5e0f-4082-e52b-232c9afa438c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-17 12:17:48.099347: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 133120000 exceeds 10% of free system memory.\n",
      "2022-04-17 12:17:48.224693: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 133120000 exceeds 10% of free system memory.\n",
      "2022-04-17 12:17:48.283850: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 133120000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 400, 400, 32)      896       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 200, 200, 32)     0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 1280000)           0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 26)                33280026  \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 33,280,922\n",
      "Trainable params: 33,280,922\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def get_cnn():\n",
    "    model = tf.keras.Sequential([\n",
    "      \n",
    "    tf.keras.layers.Conv2D(kernel_size=3, filters=32, padding='same', activation='relu', input_shape=[400, 400, 3]),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=2),\n",
    "    \n",
    "    # tf.keras.layers.Conv2D(kernel_size=3, filters=64, padding='same', activation='relu'),\n",
    "    # tf.keras.layers.MaxPooling2D(pool_size=2),\n",
    "    \n",
    "    # tf.keras.layers.Conv2D(kernel_size=3, filters=128, padding='same', activation='relu'),\n",
    "    # tf.keras.layers.MaxPooling2D(pool_size=2),\n",
    "    \n",
    "    # tf.keras.layers.Conv2D(kernel_size=3, filters=256, padding='same', activation='relu'),\n",
    "    # tf.keras.layers.MaxPooling2D(2,2),\n",
    "\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(26,'softmax')\n",
    "    ])\n",
    "\n",
    "    # opt = SGD(learning_rate=learning_rate)\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
    "    model.compile(loss= tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), optimizer=optimizer, metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])\n",
    "    # model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = get_cnn()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8787dd8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d8787dd8",
    "outputId": "38599a8f-f22c-4a1d-d299-0f264f387758"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nwoke/.local/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py:1096: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
      "  return dispatch_target(*args, **kwargs)\n",
      "2022-04-17 12:18:00.904245: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 133120000 exceeds 10% of free system memory.\n",
      "2022-04-17 12:18:00.936728: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 133120000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     12/Unknown - 45s 3s/step - loss: 7360.5508 - sparse_categorical_accuracy: 0.0312"
     ]
    }
   ],
   "source": [
    "history = model.fit(tfr_dataset, \n",
    "          # steps_per_epoch=1513/BATCH_SIZE, \n",
    "          epochs=20, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eLscUjSVwys7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 298
    },
    "id": "eLscUjSVwys7",
    "outputId": "2617192a-48ec-411f-fbc4-2fbae51043a2"
   },
   "outputs": [],
   "source": [
    "acc = history.history['sparse_categorical_accuracy']\n",
    "loss = history.history['loss']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
    "# plt.plot(acc, loss, 'r', label='loss against Training accuracy')\n",
    "plt.title('Training accuracy')\n",
    "plt.legend(loc=0)\n",
    "plt.figure()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "SbSTCEQFw-Kr",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SbSTCEQFw-Kr",
    "outputId": "5f0458e8-6490-4202-d29d-43f4521219b7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# tfr_testdata = get_dataset(VALID_FILENAMES)\n",
    "validation_array = np.array(list(tfr_testdata.unbatch().as_numpy_iterator()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "MF_JNq_uYXUo",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MF_JNq_uYXUo",
    "outputId": "b486f28c-16a5-44a4-a8f7-60e32b450081"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144\n"
     ]
    }
   ],
   "source": [
    "test_x = np.stack(validation_array[:,0])\n",
    "test_y = np.stack(validation_array[:,1])\n",
    "print(len(test_y))\n",
    "# # Use the model to predict the labels\n",
    "test_predictions = model.predict(test_x)\n",
    "test_y_pred = np.argmax(test_predictions, axis=1)\n",
    "test_y_true = test_y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ssHueiPB8i_U",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ssHueiPB8i_U",
    "outputId": "35a69938-043e-4e05-cd66-aec83fe89e9a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 4  5  6  5  0 17 25 17  8  2 19  4  9  9  0 25 16 15  2  4 14 14  4 11\n",
      "  4 20  8 18 25  0  0  6  4 14 18  7  1  2 19  1  2 11 25 13 25 14 11  6\n",
      "  4 25 20  8 25  2  2 23  4 25  0 22  0 20 22 23 13 25  2  9  5 25 11  0\n",
      " 19 11  6  8 13  4  9 14 16 24  9  8 11 13  1 11  5 25  5  5  2 24 17  1\n",
      "  5  6  3  8  0  9  5 24 17  4 17 16  2 14 17 25  1 18 15 13 25  7 17 17\n",
      " 11  5  7  1  3 15 18 17 24 13  2 16  4  0  2  1  9 14  0  2  5  5 24  5]\n",
      "[ 7  3  7  3 19 17 25 17 13  3 19  4  9 10  0 20 16 15  6  4 15 14 12 21\n",
      " 12 20 16 18 10  0  1  7  7 14 18  6  1  1 19 17 15 14  9 19 21  7 11  6\n",
      " 13 25 20  3 12 13  2 23 12  9  0 22  1 20 22 24 12 22  2 14  5 20 11  8\n",
      " 19 14  6 16 12 12  9  7 16 24  9 24 11 14  1 19  5 21 18  5 20 24 17  1\n",
      "  5  1  5 24  0  9  8 24 10  4 10  9 21 14 20 25  1 18 15 13 25  7 17 17\n",
      " 11  3  7 17  3 21 12 10 24 15  1 15  4  0  2 10  9 15  7  6  5  5 24  5]\n"
     ]
    }
   ],
   "source": [
    "print(test_y_pred)\n",
    "print(test_y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Db9lXRd3Ydql",
   "metadata": {
    "id": "Db9lXRd3Ydql"
   },
   "outputs": [],
   "source": [
    "import sklearn \n",
    "from sklearn.metrics import accuracy_score\n",
    "# Evaluating model accuracy and logging it as a scalar for TensorBoard hyperparameter visualization.\n",
    "accuracy = accuracy_score(test_y_true, test_y_pred)\n",
    "accuracy\n",
    "# tf.summary.scalar(METRIC_ACCURACY, accuracy, step=1)\n",
    "# logging.info('Test accuracy:{}'.format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f3bd3e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "47f3bd3e",
    "outputId": "042fa26b-421b-4272-a71e-775ff7bbb79a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
      "  return dispatch_target(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 1s 84ms/step - loss: 189.6040 - sparse_categorical_accuracy: 0.4931\n"
     ]
    }
   ],
   "source": [
    "tfr_testdata = get_dataset(VALID_FILENAMES)\n",
    "steps_per_epoch = 145/BATCH_SIZE\n",
    "loss, accuracy = model.evaluate(tfr_testdata\n",
    "                                # , steps_per_epoch=steps_per_epoch, BATCH_SIZE=BATCH_SIZE\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6CxRksxaKANR",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6CxRksxaKANR",
    "outputId": "322a697c-de6d-4d74-cb1d-bc47f1239ca3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "189.6040496826172\n",
      "0.4930555522441864\n"
     ]
    }
   ],
   "source": [
    "print(loss)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b704ef8",
   "metadata": {
    "id": "4b704ef8"
   },
   "outputs": [],
   "source": [
    "\n",
    "steps_per_epoch = 145/BATCH_SIZE\n",
    "y_pred = model.predict(tfr_testdata, steps_per_epoch, BATCH_SIZE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "FJS3NgyiTSYV",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FJS3NgyiTSYV",
    "outputId": "c014ce81-3710-42ba-f17e-f36912359dae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n",
      "4\n",
      "3\n",
      "14\n",
      "5\n",
      "16\n",
      "22\n",
      "9\n",
      "14\n",
      "14\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pred_len = []\n",
    "for i in range(len(y_pred[:10])):\n",
    "\n",
    "  \n",
    "  class_label = np.argmax(y_pred[i])\n",
    "  print(class_label)\n",
    "  pred_len.append(class_label)\n",
    "print(len(pred_len))\n",
    "# pred = np.argmax(y_pred, axis=1) [:]\n",
    "# test_labels = np.argmax(, axis=1) [:]\n",
    "\n",
    "# for i in range(20):\n",
    "#   print(\"predicted{}--> Expected{}\".format(pred[i], test_labels[i]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d44a0423",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d44a0423",
    "outputId": "d85bd807-ac9d-49f5-f122-2f2bde0df6b4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144\n"
     ]
    }
   ],
   "source": [
    "print(len(y_pred[:]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e23486",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "50e23486",
    "outputId": "6d613d29-fde7-4970-e3b9-82f8ae272a02"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted:  8 Actual Label: [12  5  6  3 10 21  9  9 10  2  8  9  4 19  7 24  3 10  6 15 16 11 18 24\n",
      "  0  1 24 15 25 14  9 25]\n",
      "predicted:  8 Actual Label: [14 14 12 22  9 12 15 21  1 17 16 21 12  2 17  7  7  1 14  6 13  4 17  7\n",
      "  5 20 19  7  1 14 11  6]\n",
      "predicted:  8 Actual Label: [ 1  7 15  5  5 19 18  1  7 17  2 22 20 11 24 10  9  3 12 24  5  3  3 17\n",
      "  9 13  4 14 10  0  8 15]\n",
      "predicted:  0 Actual Label: [19  7 21 20 24  0 25 16 12 24 23 12 16  5 18  9 24 20 20  5  3 18  1 13\n",
      "  0 12  6 11  5 25  0  1]\n",
      "predicted:  9 Actual Label: [ 4 14 10 19 15  7 17 21 22  1 17 19 20 13 15 20]\n"
     ]
    }
   ],
   "source": [
    "y =[]\n",
    "for (pred,(a,b)) in zip(y_pred,tfr_testdata):\n",
    "  print(\"predicted: \" , np.argmax(pred), \"Actual Label: \"+ str(b.numpy()))\n",
    "  y.append(b.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "MwlyoNdwWi0i",
   "metadata": {
    "id": "MwlyoNdwWi0i"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "American_Hand_Sign .ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
